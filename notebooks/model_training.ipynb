{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates steps of creating a pipeline of model training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- %pip install -q transformers datasets evaluate -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'nlp-project'...\n",
      "remote: Enumerating objects: 129, done.\u001b[K\n",
      "remote: Counting objects: 100% (45/45), done.\u001b[K\n",
      "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
      "remote: Total 129 (delta 16), reused 38 (delta 12), pack-reused 84 (from 1)\u001b[K\n",
      "Receiving objects: 100% (129/129), 46.71 MiB | 24.35 MiB/s, done.\n",
      "Resolving deltas: 100% (32/32), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/OopsWrongCode/nlp-project.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/nlp-project\n"
     ]
    }
   ],
   "source": [
    "%cd nlp-project/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# from datasets import Dataset\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/working/nlp-project/data/train.csv')\n",
    "test = pd.read_csv('/kaggle/working/nlp-project/data/test.csv')\n",
    "validation = pd.read_csv('/kaggle/working/nlp-project/data/valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['token_count'] = [len(sentence.split()) for sentence in train['text']]\n",
    "train['text_length'] = [len(seq) for seq in train['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>token_count</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['didnt', 'feel', 'humiliated']</td>\n",
       "      <td>sadness</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['can', 'go', 'from', 'feeling', 'so', 'hopele...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>20</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['im', 'grabbing', 'minute', 'to', 'post', 'fe...</td>\n",
       "      <td>anger</td>\n",
       "      <td>8</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['am', 'ever', 'feeling', 'nostalgic', 'about'...</td>\n",
       "      <td>love</td>\n",
       "      <td>16</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['am', 'feeling', 'grouchy']</td>\n",
       "      <td>anger</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    label  token_count  \\\n",
       "0                    ['didnt', 'feel', 'humiliated']  sadness            3   \n",
       "1  ['can', 'go', 'from', 'feeling', 'so', 'hopele...  sadness           20   \n",
       "2  ['im', 'grabbing', 'minute', 'to', 'post', 'fe...    anger            8   \n",
       "3  ['am', 'ever', 'feeling', 'nostalgic', 'about'...     love           16   \n",
       "4                       ['am', 'feeling', 'grouchy']    anger            3   \n",
       "\n",
       "   text_length  \n",
       "0           31  \n",
       "1          167  \n",
       "2           69  \n",
       "3          137  \n",
       "4           28  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['im', 'feeling', 'quite', 'sad', 'and', 'sorr...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['feel', 'like', 'am', 'still', 'looking', 'at...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['feel', 'like', 'faithful', 'servant']</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['am', 'just', 'feeling', 'cranky', 'and', 'bl...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['can', 'have', 'for', 'treat', 'or', 'if', 'a...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    label\n",
       "0  ['im', 'feeling', 'quite', 'sad', 'and', 'sorr...  sadness\n",
       "1  ['feel', 'like', 'am', 'still', 'looking', 'at...  sadness\n",
       "2            ['feel', 'like', 'faithful', 'servant']     love\n",
       "3  ['am', 'just', 'feeling', 'cranky', 'and', 'bl...    anger\n",
       "4  ['can', 'have', 'for', 'treat', 'or', 'if', 'a...      joy"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['im', 'feeling', 'rather', 'rotten', 'so', 'i...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['im', 'updating', 'my', 'blog', 'because', 'f...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['never', 'make', 'her', 'separate', 'from', '...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['left', 'with', 'my', 'bouquet', 'of', 'red',...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['was', 'feeling', 'little', 'vain', 'when', '...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    label\n",
       "0  ['im', 'feeling', 'rather', 'rotten', 'so', 'i...  sadness\n",
       "1  ['im', 'updating', 'my', 'blog', 'because', 'f...  sadness\n",
       "2  ['never', 'make', 'her', 'separate', 'from', '...  sadness\n",
       "3  ['left', 'with', 'my', 'bouquet', 'of', 'red',...      joy\n",
       "4  ['was', 'feeling', 'little', 'vain', 'when', '...  sadness"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbti_types = train['label'].unique().tolist()\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(mbti_types)\n",
    "\n",
    "train['label'] = label_encoder.transform(train['label'])\n",
    "validation['label'] = label_encoder.transform(validation['label'])\n",
    "test['label'] = label_encoder.transform(test['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f42f758ddd4c4fd489fd6727427daaac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89bc7f4ab80140aab83a592e22e63244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6ff1c4bf4e6471e929f4422de08567b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a88dc4e4f0b46a18b9f718eafb3dbf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "class MBTIDataset(Dataset):\n",
    "    def __init__(self, texts, labels=None, tokenizer=None, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.texts[index])\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_len,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        if self.labels is not None:\n",
    "            label = self.labels[index]\n",
    "            return {\n",
    "                'input_ids': encoding['input_ids'].squeeze(0),  # (max_len)\n",
    "                'attention_mask': encoding['attention_mask'].squeeze(0),  # (max_len)\n",
    "                'labels': torch.tensor(label, dtype=torch.long)\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'input_ids': encoding['input_ids'].squeeze(0),  # (max_len)\n",
    "                'attention_mask': encoding['attention_mask'].squeeze(0),  # (max_len)\n",
    "            }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max len = 60\n",
      "Min len = 2\n",
      "Avg len = 17.04\n"
     ]
    }
   ],
   "source": [
    "print(f\"Max len = {np.max(train['token_count'])}\\nMin len = {np.min(train['token_count'])}\\nAvg len = {np.round(np.mean(train['token_count']), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "MAX_LEN = np.max(train['token_count'])\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_dataset = MBTIDataset(texts=train['text'].tolist(), labels=train['label'].tolist(), tokenizer=tokenizer, max_len=MAX_LEN)\n",
    "test_dataset = MBTIDataset(texts=test['text'].tolist(),labels=test['label'].tolist(), tokenizer=tokenizer, max_len=MAX_LEN)\n",
    "validation_dataset = MBTIDataset(texts=validation['text'].tolist(), labels=validation['label'].tolist(), tokenizer=tokenizer, max_len=MAX_LEN)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For regularization, we employ two commonly used\n",
    "techniques: dropout (Hinton et al., 2012) and L2\n",
    "weight regularization. We apply dropout to prevent co-adaptation. In our model, we either apply\n",
    "dropout to word vectors before feeding the sequence\n",
    "of words into the convolutional layer or to the output\n",
    "of LSTM before the softmax layer. The L2 regularization is applied to the weight of the softmax layer. (https://arxiv.org/pdf/1511.08630)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, output_dim=6, num_layers=1, bidirectional=False, dropout=0.3, fc_dropout=0.3, input_dropout=0.2):\n",
    "        super(MyLSTM, self).__init__()\n",
    "\n",
    "        \n",
    "        self.input_dropout = nn.Dropout(input_dropout) # \n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_dim, # 768\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=bidirectional,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            batch_first=True\n",
    "        )\n",
    "        # LAYER 2: Fully-connected\n",
    "        self.fc_dropout = nn.Dropout(fc_dropout)\n",
    "        self.fc = nn.Linear(\n",
    "            hidden_dim * (2 if bidirectional else 1),\n",
    "            output_dim\n",
    "        )\n",
    "\n",
    "    def forward(self, bert_embeddings):  # [batch_size, seq_len, embedding_dim]\n",
    "\n",
    "        # Dropout on BERT-embeddings\n",
    "        x = self.input_dropout(bert_embeddings)\n",
    "\n",
    "        lstm_output, (h_n, c_n) = self.lstm(x)\n",
    "\n",
    "        if self.lstm.bidirectional:\n",
    "            h_final = torch.cat((h_n[-2], h_n[-1]), dim=1)\n",
    "        else:\n",
    "            h_final = h_n[-1]\n",
    "\n",
    "        h_final = self.fc_dropout(h_final)\n",
    "        out = self.fc(h_final)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGRU(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, output_dim=6, num_layers=1, bidirectional=False, dropout=0.3, fc_dropout=0.1):\n",
    "        super(MyGRU, self).__init__()\n",
    "\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=bidirectional,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc_dropout = nn.Dropout(fc_dropout)\n",
    "        self.fc = nn.Linear(hidden_dim * (2 if bidirectional else 1), output_dim)\n",
    "\n",
    "    def forward(self, x): \n",
    "        gru_output, h_n = self.gru(x)\n",
    "\n",
    "        if self.gru.bidirectional:\n",
    "            h_final = torch.cat((h_n[-2], h_n[-1]), dim=1)\n",
    "        else:\n",
    "            h_final = h_n[-1]\n",
    "\n",
    "        h_final = self.fc_dropout(h_final)\n",
    "        out = self.fc(h_final)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C-LSTM: https://arxiv.org/pdf/1511.08630\n",
    "\n",
    "class HybridNN(nn.Module):\n",
    "    def __init__(self, embedding_dim=768, conv_out_channels=256, kernel_size=3, \n",
    "                 hidden_dim=256, output_dim=6, lstm_layers=2, bidirectional=True, \n",
    "                 dropout=0.4, fc_dropout=0.2, input_dropout=0.1):\n",
    "        super(HybridNN, self).__init__()\n",
    "\n",
    "        self.input_dropout = nn.Dropout(input_dropout)\n",
    "\n",
    "        # CNN block\n",
    "        self.conv1 = nn.Conv1d(in_channels=embedding_dim,\n",
    "                               out_channels=conv_out_channels,\n",
    "                               kernel_size=kernel_size,\n",
    "                               padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=conv_out_channels,\n",
    "                               out_channels=conv_out_channels,\n",
    "                               kernel_size=kernel_size,\n",
    "                               padding=1)\n",
    "\n",
    "        self.spatial_dropout = nn.Dropout2d(0.3)\n",
    "        self.gelu = nn.GELU()\n",
    "\n",
    "        # LSTM\n",
    "        self.lstm = nn.LSTM(input_size=conv_out_channels,\n",
    "                            hidden_size=hidden_dim,\n",
    "                            num_layers=lstm_layers,\n",
    "                            bidirectional=bidirectional,\n",
    "                            dropout=dropout if lstm_layers > 1 else 0,\n",
    "                            batch_first=True)\n",
    "\n",
    "        self.attn_linear = nn.Linear(hidden_dim * (2 if bidirectional else 1), 1)\n",
    "\n",
    "        # Output\n",
    "        self.fc_dropout = nn.Dropout(fc_dropout)\n",
    "        self.fc = nn.Linear(hidden_dim * (2 if bidirectional else 1), output_dim)\n",
    "\n",
    "    def forward(self, embeddings):\n",
    "        # Dropout input\n",
    "        x = self.input_dropout(embeddings)  # [batch_size, seq_len, embedding_dim]\n",
    "        # Conv1D\n",
    "        x = x.permute(0, 2, 1)                 # [B, seq, emb]\n",
    "        x = self.gelu(self.conv1(x))\n",
    "        x = self.gelu(self.conv2(x))\n",
    "        x = x.permute(0, 2, 1)                 # LSTM\n",
    "        x = self.spatial_dropout(x) \n",
    "\n",
    "\n",
    "        # LSTM\n",
    "        lstm_out, _ = self.lstm(x)  # [batch_size, seq_len, hidden_dim*2]\n",
    "\n",
    "        # Attention mechanism\n",
    "        attn_weights = torch.softmax(self.attn_linear(lstm_out), dim=1)  # [batch_size, seq_len, 1]\n",
    "        attn_output = torch.sum(lstm_out * attn_weights, dim=1)  # [batch_size, hidden_dim*2]\n",
    "\n",
    "        # FC\n",
    "        out = self.fc_dropout(attn_output)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c27463ed3b26413d96b5156e738e9750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "bert = AutoModel.from_pretrained(\"bert-base-uncased\").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(train.label), y=train.label)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.2350, 1.3769, 0.4975, 2.0489, 0.5706, 4.6857], device='cuda:0')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_weights[5] = class_weights[5] * 1.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
    "# VOCAB_SIZE = len(tokenizer)\n",
    "\n",
    "gru_model = MyGRU(embedding_dim=768, hidden_dim=128, output_dim=6, num_layers=5, dropout=0.3,fc_dropout=0.2, bidirectional=True).to(DEVICE)\n",
    "\n",
    "gru_optimizer = optim.Adam(gru_model.parameters(), lr=0.001)\n",
    "gru_scheduler = ReduceLROnPlateau(gru_optimizer, patience=3, factor=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_weights[5] = class_weights[5] * 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = MyLSTM(embedding_dim=768, hidden_dim=128, output_dim=6, num_layers=2, dropout=0.5, bidirectional=True).to(DEVICE)\n",
    "\n",
    "lstm_optimizer = optim.Adam(lstm_model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "lstm_scheduler = ReduceLROnPlateau(lstm_optimizer, patience=3, factor=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_model = HybridNN(embedding_dim=768, conv_out_channels=128, kernel_size=4, \n",
    "                 hidden_dim=128, output_dim=6, lstm_layers=2, bidirectional=True, \n",
    "                 dropout=0.4, fc_dropout=0.2, input_dropout=0.1).to(DEVICE)\n",
    "\n",
    "hybrid_optimizer = optim.Adam(hybrid_model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "hybrid_scheduler = ReduceLROnPlateau(hybrid_optimizer, patience=3, factor=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, model, patience=3, min_delta=0.01, restore_best_weights=True, save_weights=False):\n",
    "        self.model = model\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = float('inf')\n",
    "        self.best_weights = None\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        self.save_weights = save_weights\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss - self.min_delta:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "            if self.restore_best_weights:\n",
    "                self.best_weights = copy.deepcopy(self.model.state_dict())\n",
    "\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                if self.restore_best_weights and self.best_weights is not None:\n",
    "                    self.model.load_state_dict(self.best_weights)\n",
    "                    if self.save_weights:\n",
    "                        torch.save(self.best_weights, f'{self.model.__class__.__name__}_best_weights.pt')\n",
    "                        print(f\"Weights has been saved\")\n",
    "                return True\n",
    "\n",
    "        return False\n",
    "\n",
    "# source: https://stackoverflow.com/questions/71998978/early-stopping-in-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 — Train Loss: 1.7446 | Val Loss: 1.6574 | Val Acc: 0.1927\n",
      "Epoch 2/25 — Train Loss: 1.5875 | Val Loss: 1.5415 | Val Acc: 0.4449\n",
      "Epoch 3/25 — Train Loss: 1.5164 | Val Loss: 1.4982 | Val Acc: 0.2107\n",
      "Epoch 4/25 — Train Loss: 1.3339 | Val Loss: 1.2724 | Val Acc: 0.3829\n",
      "Epoch 5/25 — Train Loss: 1.1819 | Val Loss: 1.1049 | Val Acc: 0.4204\n",
      "Epoch 6/25 — Train Loss: 1.1154 | Val Loss: 1.0185 | Val Acc: 0.4309\n",
      "Epoch 7/25 — Train Loss: 1.0439 | Val Loss: 0.9915 | Val Acc: 0.6001\n",
      "Epoch 8/25 — Train Loss: 0.9405 | Val Loss: 0.8598 | Val Acc: 0.6466\n",
      "Epoch 9/25 — Train Loss: 0.8360 | Val Loss: 0.8052 | Val Acc: 0.7247\n",
      "Epoch 10/25 — Train Loss: 0.7510 | Val Loss: 0.7851 | Val Acc: 0.7257\n",
      "Epoch 11/25 — Train Loss: 0.6919 | Val Loss: 0.6994 | Val Acc: 0.7367\n",
      "Epoch 12/25 — Train Loss: 0.6894 | Val Loss: 0.6847 | Val Acc: 0.7362\n",
      "Epoch 13/25 — Train Loss: 0.6496 | Val Loss: 0.6775 | Val Acc: 0.7207\n",
      "Epoch 14/25 — Train Loss: 0.6218 | Val Loss: 0.6170 | Val Acc: 0.7427\n",
      "Epoch 15/25 — Train Loss: 0.5934 | Val Loss: 0.6382 | Val Acc: 0.7723\n",
      "Epoch 16/25 — Train Loss: 0.5790 | Val Loss: 0.6165 | Val Acc: 0.7673\n",
      "Epoch 17/25 — Train Loss: 0.5658 | Val Loss: 0.6369 | Val Acc: 0.7412\n",
      "Epoch 18/25 — Train Loss: 0.5610 | Val Loss: 0.6046 | Val Acc: 0.7838\n",
      "Epoch 19/25 — Train Loss: 0.5471 | Val Loss: 0.6220 | Val Acc: 0.7477\n",
      "Epoch 20/25 — Train Loss: 0.5298 | Val Loss: 0.6331 | Val Acc: 0.7813\n",
      "Epoch 21/25 — Train Loss: 0.5214 | Val Loss: 0.6188 | Val Acc: 0.7603\n",
      "Epoch 22/25 — Train Loss: 0.5187 | Val Loss: 0.5844 | Val Acc: 0.7803\n",
      "Epoch 23/25 — Train Loss: 0.5129 | Val Loss: 0.6014 | Val Acc: 0.7563\n",
      "Epoch 24/25 — Train Loss: 0.5328 | Val Loss: 0.5898 | Val Acc: 0.7723\n",
      "Epoch 25/25 — Train Loss: 0.5182 | Val Loss: 0.6327 | Val Acc: 0.7688\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.77       274\n",
      "           1       0.90      0.66      0.76       212\n",
      "           2       0.88      0.76      0.82       703\n",
      "           3       0.46      0.84      0.59       178\n",
      "           4       0.89      0.78      0.83       550\n",
      "           5       0.46      0.88      0.60        81\n",
      "\n",
      "    accuracy                           0.77      1998\n",
      "   macro avg       0.73      0.78      0.73      1998\n",
      "weighted avg       0.82      0.77      0.78      1998\n",
      "\n",
      "Train finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "EPOCHS = 25\n",
    "MODEL = hybrid_model\n",
    "OPTIMIZER = hybrid_optimizer\n",
    "lr_history = []\n",
    "early_stopper = EarlyStopper(patience=4, model=MODEL, min_delta=0.01, save_weights=False)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    MODEL.train() #replace\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        OPTIMIZER.zero_grad() # replace\n",
    "\n",
    "        input_ids = batch['input_ids'].to(DEVICE)\n",
    "        attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "        labels = batch['labels'].to(DEVICE)\n",
    "\n",
    "        with torch.no_grad():  # BERT embed\n",
    "            bert_output = bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            embeddings = bert_output.last_hidden_state  # [batch_size, seq_len, 768]\n",
    "\n",
    "        outputs = MODEL(embeddings) #replace\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        OPTIMIZER.step() #replace\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "\n",
    "    # === VALIDATION ===\n",
    "    MODEL.eval() #replace\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "    val_loss_total = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in validation_loader:\n",
    "            input_ids = batch['input_ids'].to(DEVICE)\n",
    "            attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "            labels = batch['labels'].to(DEVICE)\n",
    "\n",
    "            bert_output = bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            embeddings = bert_output.last_hidden_state\n",
    "\n",
    "            outputs = MODEL(embeddings) #replace\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            val_loss_total += loss.item()\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            val_preds.extend(preds.cpu().numpy())\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = val_loss_total / len(validation_loader)\n",
    "    val_acc = accuracy_score(val_labels, val_preds)\n",
    "\n",
    "    hybrid_scheduler.step(avg_val_loss) # replace \n",
    "    current_lr = OPTIMIZER.param_groups[0]['lr'] #replace\n",
    "    lr_history.append(current_lr)\n",
    "\n",
    "    if early_stopper.early_stop(avg_val_loss):             \n",
    "        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} — Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "class_report = classification_report(val_labels, val_preds, target_names=[str(i) for i in range(6)])\n",
    "print(f\"Classification Report:\\n{class_report}\")\n",
    "\n",
    "print(\"Train finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best weights loaded after training\n"
     ]
    }
   ],
   "source": [
    "if early_stopper.best_weights is not None:\n",
    "    MODEL.load_state_dict(early_stopper.best_weights)\n",
    "    print(\"Best weights loaded after training\")\n",
    "else:\n",
    "    print(\"No best weights were saved (maybe early stop didn’t trigger?)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6805 | Validation Accuracy: 0.7750\n"
     ]
    }
   ],
   "source": [
    "MODEL.load_state_dict(early_stopper.best_weights)\n",
    "MODEL.eval()\n",
    "\n",
    "test_preds = []\n",
    "test_labels = []\n",
    "test_loss_total = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(DEVICE)\n",
    "        attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "        labels = batch['labels'].to(DEVICE)\n",
    "\n",
    "        bert_output = bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        embeddings = bert_output.last_hidden_state\n",
    "\n",
    "        outputs = MODEL(embeddings)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        test_loss_total += loss.item()\n",
    "\n",
    "\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        test_preds.extend(preds.cpu().numpy())\n",
    "        test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "\n",
    "\n",
    "avg_test_loss = test_loss_total / len(test_loader)\n",
    "test_acc = accuracy_score(test_labels, test_preds)\n",
    "\n",
    "print(f\"Validation Loss: {avg_test_loss:.4f} | Validation Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, len(lr_history) + 1), lr_history)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Learning Rate Schedule\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
